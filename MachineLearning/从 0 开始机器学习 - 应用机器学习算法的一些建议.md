提纲：

1. 引言：说明为何需要评估算法
2. 训练集、交叉验证集，测试集
3. 多项式次数和偏差方差的关系
4. 正则化系数和偏差方差的关系
5. 学习曲线（m - error）
6. 使用评估方法来决定下一步做什么

## 一、如何确定下一步的计划？

当我们设计了一个机器学习算法，比如线性回归或逻辑回归，并且算法已经能够正常工作，只是效果还不是太好，那用什么方法来提高算法的性能或者准确度呢？或者说在想办法提升性能之前，有没有一种方法来告诉我们下一步对我们设计的机器学习算法该采取什么步骤，比如：

1. 获得更多的训练样本
2. 尝试减少特征的数量
3. 尝试获得更多的特征
4. 尝试增加多项式特征
5. 尝试减少正则化程度
6. 尝试增加正则化程度

上面 6 种思路都可以作为提升一个算法性能的选择，可是我们对一个算法到底该选择哪一种优化的思路呢？今天就跟大家分享下如何来评估一个机器学习算法，也称为**机器学习诊断法**，这个方法可以明确地告诉我们：**要想进一步提升算法的性能，我们到底该采取什么方法是比较有效地，是增加训练集数量，还是增加或者减少特征数等。**

使用这个方法的必要性是可以帮助我们节省时间，让我们可以更加明确优化算法的方向，不至于像无头苍蝇一样胡乱的选择优化思路，最终效果还不行。

## 二、训练集、交叉验证集，测试集

在学习诊断法之前，需要先对训练数据集进行处理。对于特征变量比较少的情况，我们可以直接画出假设函数在训练集上的拟合效果，比如：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/evaluating_hypothesis.png)

但是当特征数量很多以至于不能用曲线表示拟合效果时，就需要用另外一种代价函数误差指标的方法来衡量假设函数的拟合效果，为此需要把原始数据集进行拆分：

- 70% 作为训练集 `training set`
- 30% 作为测试集 `test set` 

这样我们就有了用来评估模型效果的测试数据集了，首先把模型再训练集和进行训练，然后用测试集计算模型的代价函数误差 $J(\theta)$，但是不能适应一般情况（？？？），为此再对数据集拆分：

- 60% 作为训练集 `training set`
- 20% 作为交叉验证集 `cross validation set`
- 20% 作为测试集 `test set `

之后使用这 3 个数据集对多个模型进行训练或者评估：

1. 在训练集上训练个模型，并计算训练误差 $J_{train}(\theta)$
2. 在交叉验证集上计算代价函数的交叉验证误差 $J_{cv}(\theta)$
3. 选择交叉验证误差最小的模型
4. 在测试集上计算上一步选择的最小模型的代价函数推广误差 $J_{test}(\theta)$

接下来我们分别在训练集和交叉验证集上用曲线做对比分析，以此来分析当前算法存在**高偏差问题**还是**高方差问题**。

## 三、多项式次数与偏差和方差的曲线

通过之前博客的学习我们已经知道：

- 高偏差问题：模型欠拟合 （underfitting）
- 高方差问题：模型过拟合（overfitting）

通过前面拆分的训练集合交叉验证集，我们可以画出一个模型的多项式次数 - 代价函数误差的曲线，以此通过曲线来帮助我们分析当前的模型是欠拟合还是过拟合，比如下面的曲线：

解释下：

- 横坐标代表假设函数（模型）的多项式次数 `d`
- 纵坐标表示代价函数的误差 `error`
- $J_{cv}(\theta)$ 表示模型在交叉验证集上的代价函数误差
- $J_{train}(\theta)$ 表示模型在训练集上的代价函数误差

从曲线中我们可以发现 3 个关键的位置及其含义：

1. 多项式次数较低：$J_{cv}(\theta)$ 与 $J_{train}(\theta)$ 误差近视

## 四、正则化系数与偏差和方差的曲线



