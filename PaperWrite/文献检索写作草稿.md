## 1 摘要

### 1.1  框架

1. 为何需要这项技术？
2. 这篇文章提出了什么创新的方法来完成这项工作?
3. 分别介绍每个模块的主要作用
4. 介绍实验分析与优点

### 1.2 内容

为了在道路上导航，自动驾驶车辆必须能够感知和识别三维环境中的物体，对周围环境高层次的理解对于计划和执行准确的驾驶很有必要，目前常用的方法是基于雷达和相机融合构建的语义地图来感知周围环境。这种方法主要分为 4 个模块：首先，我们需要标定雷达和相机，以保证 2 者的坐标系对齐。然后使用 CNN  对图像进行语义分割并获取每个像素标签的概率分布。第三步将每个像素的语义信息和概率分布与对齐的点云进行数据关联，以此获得语义点云。最后，我们把获取的语义点云作为八叉树地图构建算法的输入，该算法会自动更新节点的占据和标签概率，并完成增量式的地图构建。我们在自己的平台和公开的 KITTI 数据集都进行了测试，验证了该方法的有效性。

## 2 文献检索

### 2.1 框架

- 用什么关键字检索？或者从哪一篇论文开始检索？
- 检索得到哪些结果？如何过滤检索结果？得到哪些有用的信息？
- 目前你检索的领域的研究现状如何？热度如何？主要有哪些大牛？ 
- 为什么选这几个刊物？你是如何决定选择这6篇论文的？

### 2.2 内容

在开始检索前，我粗略了阅读了一些质量一般的文章的摘要，主要目的是为了获取该领域常用的关键字。在初步了解后，我在 SCI 上主要使用 3 组关键字进行检索：semantic mapping、octree large semantic 3D mapping、lidar camera semantic 3D Mapping。

在检索前设置检索时间跨度为 2016 - 2020 年，以 semantic 3D mapping 关键字为例检索结果如下：



因为检索结果很多，所以首先分析检索结果，选择英国、美国地区进行过滤：



在过滤地区后的检索结果中，再次对结果进行精炼选择，主要对出版物类别、文献类型、出版机构、出版物的来源这 4 项进行单独或者结合的精炼：



然后对精炼后的结果进行排序。



## 3 精读一篇

### 3.1 选择原因

我选择精读的是 2018 年 IROS 的文章，选择这篇精读的主要原因有 4 点：期刊影响力，摘要、方法框架、实验结果。IROS 是机器人领域的顶级会议，该文章的摘要对论文的方法框架进行了初步的介绍，文章的方法框架对我目前的研究方向非常具有借鉴意义，并且实验结果在独立的平台测试，该篇文章引用了一篇建图领域非常经典的 Octomap 建图论文，综上我选择了这篇文章进行精读。

### 3.2 Introduction

论文主要解决的问题是使用低成本稀疏的激光雷达和图像进行大范围八叉树地图构建，以此来为机器人室外导航提供环境地图。导航地图是机器人感知环境必不可少的一部分，只有构建出机器人周围的环境地图，才能实现最优路径规划、可靠的驾驶决策和准确的车辆控制导航等应用。

在以往的语义地图构建中大多采用单目 RGB-D 相机进行地图构建，这种方法存在的问题是相机产生的点云对于远距离的物体误差较大，没有直接使用激光雷达获取的点云精度高，导致最终的语义地图构建误差较大，并且使用一个独立的相机会使得系统的容错性不足，在一些恶劣的环境下，大大影响建图的效果，而基于雷达与相机的传感器融合建图则可以弥补这个缺陷。

目前的研究现状逐渐像多传感器融合方向发展，通过融合算法可以克服每一种单独感知方式的限制，同时利用它们的最佳能力，这篇文章通过融合视觉系统与 3D 雷达测距系统，使得机器人能更加全面地了解周围环境。

### 3.3 Methods

#### 3.3.1 方法框架

这篇文章采用的是经典的 Pipeline 框架，通过集成建图工作中目前用到的各种最新技术模块，一步步确定项目的技术流程管道：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_Flowchart.png)

使用的理论依据主要分为以下 X 部分。

#### 3.3.2 语义标签概率关联

为了获取语义信息，需要对图像进行语义分割，目前效果最好的方法是基于卷积神经网络来对图像进行语义分割，本文中使用提前在 Cityscapes 数据集上训练好的 E-Net 网络进行分割，分割的类别一共有 12 类：'sky'，'building'，'pole'，'road'，'undrivable road'，'vegetation'，'sign symbol'，'fence'，'vehice'，'pedestrian'，'rider'，'unlabeled'，分割的效果如下：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_CNN_ENet.png)

通过语义分割将图像中每个像素进行分类后，还需要求出每个像素分类的概率，因为最后的语义融合需要使用语义分割计算的概率分布。为此，在 CNN 分割之后，我们通过整合原始图像超像素边界与语义图像的叠加图像，以及 CNN 分割后的得分图，以此将不确定性与每个像素标签关联起来。

首先需要获得原始图像产生的超像素对每个标签的评估，超像素是一种区域分割方法，每个元素包含的像素都是根据区域间和区域内特征的相似性进行分组的，这些特征包括颜色、纹理、亮度、轮廓、曲线连续性等。每个超像素都是一个感知一致的单元，因为里面的所有像素都很可能是一致的，超像素分割算法如下：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_superpixel.png)

算法的输入是：原始图像 I、语义分割图像 Labels、期望的超像素个数 n_sp，输出是关联了不确定性的超像素概率分布图像：Spp_map。

该算法首先创建与原始图像相同大小的输出变量 SSpmap。然后采用简单的线性迭代聚类 SLIC 方法对原始图像进行分割，选择该方法是基于其速度、存储效率和遵守边界的特点，以下是 SLIC 对图像进行超像素分割的结果：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/superpixel_result.png)

下一步基于 CNN 语义分割对每个超像素评估最常见类别的百分比，它被计算并存储在输出变量的相应坐标中，输出变量 Sppmap 像素属于单一类的超像素的最大值为 1，带有多个标签的超像素会根据占主导地位的类所占据的区域有较小的值，以下是语义图像超像素分割和对应超像素概率分布的结果：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_semantic_labels.png)

接着我们需要进行第二个不确定性关联的步骤，即叠加 CNN 分割的得分图，我们对 CNN 的输出使用一个 softmax 函数来产生每个像素类别的概率分布。

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_softmax.png)

式中，theta 表示所有训练好的 CNN 参数，为了获得一个包含每个像素最大概率的分布，我们导出每个像素最大概率的类别分布：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_max_p_map.png)

P_map 的结果如下图：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_cnn_score_map.png)

最后将超像素分割的结果 Spp_map 和 CNN score map 得到的 P_map 进行整合：
$$
Smap = Pmap * Spp_{map}
$$


最终的标签概率分布 Smap 如下：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/IROS_S_map.png)

#### 3.3.3 3D 投影

在融合语义之前，需要将相机坐标系与雷达坐标系进行对齐，对齐的方法对雷达和相机进行外参标定，以此得到 2 者之间的旋转和平移矩阵，另一个错误来源是由于图像和点云之间存在的不对准，这可能导致分配错误的标签。针对此问题，提出了一种基于单个扫描环聚类的投票校正方法

