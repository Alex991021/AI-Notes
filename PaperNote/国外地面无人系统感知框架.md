[Toc]

## 二、国外地面无人系统环境感知技术路径

### 2.1 技术路径总结

环境感知主要使用雷达和相机这 2 个传感器，基本的技术模块主要包括以下 4 大部分：

1. 雷达相机联合标定
2. 环境感知（图像、点云单独或者融合）
   - 道路识别
   - 障碍物检测
   - 目标跟踪
   - 其他应用...

3. 位姿估计
4. 环境地图构建

### 2.2 Environmental Perceptionand Sensor Data Fusion for Unmanned Ground Vehicle (2013)

本文主要介绍地面无人系统环境感知数据融合的底层和上层方法：

- 卡尔曼滤波用于底层融合
- D-S 证据理论用于高层融合
- 概率测试和高斯混合模型用来识别可通过区域

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/UGV-environment-perception.png)

- 论文：[Environmental Perceptionand Sensor Data Fusion for Unmanned Ground Vehicle (2013)](https://www.hindawi.com/journals/mpe/2013/903951/)

### 2.3 A Perception Pipeline for Expeditionary Autonomous Ground Vehicles (NASA JPL 2017)

本文介绍了一种用于军队远征的地面无人平台的环境感知管道：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/perception_pipeline_2.png)

#### 2.3.1 传感器标定

- 相机内参标定
- 雷达和相机的外参标定

#### 2.3.2 传感器数据处理

主要对图像和点云数据进行预处理：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/sensor_process.png)

- 图像：滤波
- 点云：地面和目标分割

#### 2.3.3 目标分类与检测

使用学习的方法对地面分类和障碍物检测：

- 决策树
- CNN

#### 2.3.4 环境地图

构建八叉树栅格地图（OctoMap）作为世界模型用于导航：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/MAGV_octomap.png)

- 论文：[A Perception Pipeline for Expeditionary Autonomous Ground Vehicles (NASA JPL 2017)](https://spie.org/Publications/Proceedings/Paper/10.1117/12.2266690?SSO=1)

### 2.4 Autonomous Navigation for BigDog（Boston Dynamics 2010）

#### 2.4.1 地面平台

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/bigdog-robot.png)

#### 2.4.2 软件系统框架

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/bigdog-soft-arch.png)

#### 2.4.4 环境感知模块

(1) 雷达相机标定、图像点云数据预处理：使用 LIDAR 和双目相机作为主要的感知传感器，需要对这两者标定，并预处理数据。

(2) 点云分割与目标跟踪：

- 第一步是将 LIDAR 点云和基于立体的地形图提供的障碍点分割成不同的对象，通过合并相距不到 0.5 米的单个点，将稀疏的 3D 点云分割为单个对象。
- 随时间推移跟踪由分割算法产生的对象，采用具有启发式约束的贪婪迭代算法来完成此任务，通过将点云分割为对象并随时间进行跟踪，该机器人可以在地面坡度变化适中且障碍物种类繁多的环境中适当运行，这些障碍物包括树木，巨石，倒下的原木，墙壁。
- 树木和墙壁主要由 LIDAR 识别，巨石和倒下的原木由立体视觉系统识别

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/bigdog-perception.png)

(3) 构建环境地图：用于全局导航路径规划，此项目使用 2D 网格地图。

- 论文：[Autonomous Navigation for BigDog（Boston Dynamics 2010）](https://ieeexplore.ieee.org/document/5509226)

### 2.5 Toward Reliable Off Road Autonomous Vehicles Operating in Challenging Environments（CMU Robotics Institute 2006）

CMU DARPA PerceptOR 项目！这篇文章被多次引用。

#### 2.5.1 地面平台

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/CMU_UGV.png)

#### 2.5.2 软件架构

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/CMU_soft_arch.png)

#### 2.5.3 环境感知模块

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/CMU_perception_arch.png)

感知模块主要分为 3 部分：

- 传感器标定、数据预处理
- 目标分类与检测
- 建立环境地图

- 论文：[Toward Reliable Off Road Autonomous Vehicles Operating in Challenging Environments](http://www.cse.psu.edu/~buu1/teaching/fall06/uuv/papers/Optimizations-Evaluations/KellyStentz.pdf)

### 2.6 A CPU-GPU Hybrid System of Environment  Perception and 3D Terrain Reconstruction for  Unmanned Ground Vehicle（2018）

#### 2.6.1 环境感知模块

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/perception_reconstruction_arch.png)

主要分为以下 3 部分：

1. 传感器标定和预处理
   - 联合标定、数据滤波，坐标系转换等
2. 环境感知
   - 物体的分割、识别、检测，语义地图构建
3. 环境重建

论文：[A CPU-GPU Hybrid System of Environment  Perception and 3D Terrain Reconstruction for  Unmanned Ground Vehicle（2018）](https://www.researchgate.net/publication/330309566_A_CPU-GPU_hybrid_system_of_environment_perception_and_3D_terrain_reconstruction_for_unmanned_ground_vehicle)

### 2.7 Robotics Collaborative Technology Alliance (RCTA) Program Overview (ARL US Army’s manned-unmanned teaming 2018)

RCTA 计划是 ARL 与学术和行业合作伙伴组成的联盟，该计划于 2010 年授予，预计将于 2019 年初结束，该计划在基础地面机器人技术方面进行前沿研究，其总体目标是从远程操作到自主机器人，该研究满足美国陆军的无人驾驶联队（MUMT）的要求，该计划的四个研究重点领域是：感知，智能，人机交互，灵巧操纵。

#### 2.7.1 软件架构

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/RCTA_soft_architecture.png)

- 论文：[Robotics Collaborative Technology Alliance (RCTA) Program Overview](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10640/106400D/Robotics-collaborative-technology-alliance-RCTA-program-overview/10.1117/12.2314662.short?SSO=1)

### 2.8 An integrated perception pipeline for robot mission execution in unstructured environments（2020）

本文侧重于介绍环境感知中的目标检测 Pipeline。

#### 2.8.1 环境感知框架

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/cmu_perception_pipeline.png)

#### 2.8.2 感知任务

- 目标检测：Fast-R-CNN
- 位姿估计：基于姿态估计的语义关键点算法

#### 2.8.3 Perception Pipeline

1. 数据采集
2. 数据标注
3. 数据扩充
4. 模型训练与评估

- 论文：[An integrated perception pipeline for robot mission execution in unstructured environments](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11413/1141318/An-integrated-perception-pipeline-for-robot-mission-execution-in-unstructured/10.1117/12.2560699.short)

### 2.9 Achieving integrated convoys: Cargo Unmanned Ground Vehicle development and experimentation（2013 USA Cargo）

#### 2.9.1 地面平台

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/UGV_cargo.png)

#### 2.9.2 系统软件架构

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/system_arch.png)

#### 2.9.3 感知模块（激光雷达 + 毫米波雷达）

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/terrain_deection.png)

1. 激光雷达与毫米波融合
2. 地面检测：机器学习
3. 地面分类：机器学习
4. 移动障碍物检测：卡尔曼滤波
5. 构建代价地图

- 论文：[Achieving integrated convoys: Cargo Unmanned Ground Vehicle development and experimentation](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8741/87410Y/Achieving-integrated-convoys--cargo-unmanned-ground-vehicle-development-and/10.1117/12.2015586.short)

### 2.10 Learning for autonomous navigation（2010 Crusher USA）

#### 2.10.1 地面平台

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/UPI.png)

#### 2.10.2 软件架构

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/arch.png)

本文的环境感知模块主要侧重于：

1. 使用相机和雷达基于学习的方法进行地面感知分类
2. 构建代价地图

- 论文：[Learning for autonomous navigation](https://ieeexplore.ieee.org/document/5481587)

### 2.11 Remote operation of the Black Knight unmanned ground combat vehicle（2008 UK）
#### 2.11.1 地面平台

感知模块主要使用 2 个双目相机和 4 个雷达。

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/black-knight.png)

#### 2.11.2 整体软件架构

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/arch_back_knight.png)

#### 2.11.2 感知模块

本文感知模块的主要任务是：估计地面位置、检测障碍物和地面。

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/perception_module.png)

感知流程：

1. 所有导航传感器与机体坐标系标定
2. Scroll Map：雷达点云与相机融合，结合 GPS/IMU 构建稠密 3D 点云地图
3. Ground Height Estimator：从地面检测道路沟渠、陡坡、不同的障碍物需要保证一个安全的地面环境。
4. Sloper Estimator：从 Ground Estimator 中计算可能会车辆造成危险的陡坡。
5. Density Estimator：构建 3D 体素网格地图用于寻找障碍物
6. Tall Object Estimator：检测地面上的障碍物区域

- 论文：[Remote operation of the Black Knight unmanned ground combat vehicle]([https://www.google.com/search?q=Remote%20operation%20of%20the%20Black%20Knight%20unmanned%20ground%20combat%20vehicle&ie=utf-8](https://www.google.com/search?q=Remote operation of the Black Knight unmanned ground combat vehicle&ie=utf-8))